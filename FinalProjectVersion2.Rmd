---
title: "Busines Data Analytics Final Project"
author: "John Chrusciel Jr & Matthew Salmon"
date: "29 October 2018"
output:
  word_document: default
  html_document:
    df_print: paged
subtitle: BSAD 443 - Professor Osman S. Abraz
---
### 1. Executive Summary


```{r}

```

### 2. Business Understanding

#### 2.1 Data Sizing & Description

This analysis is based entirely on the data we received from the entity engaging our academic/consulting  services. Although every reasonable and prudent attempt has been made to ensure that commonly accepted and sound business data analytics principles have been adhered to during the performance of the work covered under the scope our our agreement, we must add the caveat that the results and recommendations we are making are based on data provided to us by your organization. 

We were provided with two data sets, the training data set consisting of the HR records of 10,000 current and separated employees and a smaller testing data set composed of the records of 5,000 other different current and separated employees which we assume was not included in the training data set. We are also operating under the assumption that the data sets were properly sampled and partitioned. 

Proceding forward with the understanding that both data sets were generated by the sponsoring organization without our technical oversight, the ultimate validity of the analysis, assessments, and recommendations we have formed under the scope of our engagement must be intrerpreted of light of this risk.

Both the Training Data Set (TRDS) and the Testing Data Set (TEDS) were received electronically via an MS Excel Workbook attached to an email from the sponsor's HR Department. The workbook (HR.xsls) consisted of two tabbed pages, one tab named "Training"" contained the with the training data, the other tab labelled "Testing" which contained the testing data. 

File HR.xlsx was created by the sponsor on 04/16/2017 at 5:06 PM and was last saved by our sponsor on 10/10/2018 at 5:30 PM. The file was transmitted to and received by our organization with a size of 668 KB on 10/26/2018. The content type is application/vnd.openxmlformats-officedocument.spreadsheetml.sheet. 

The data is structured and is of mixed type, both numerical and categorical. The information contained is proprietary and can be considered confidential. 

The TRDS, as received, in it's native Microsoft Excel format is 10,001 rows long including the header row. Each row has 10 attributes. The TEDS is similarly structured except that it is 5,000 rows long. 

Both datasets are structured exactly the same. The attributes (columns)
are as follows: 

**satisfaction_level:** This is Categoric Ordinal Data ranked from 0 to 1. A value approaching 1 is associated with high job satisfaction and a value nearing zero can be associated with low job satisfaction.

We are assuming that this is the job satisfaction value was self-reported during the employees most recent formal review. For those employees separated from service, we do not know if this score was recorded from information disseminated during their normal assessment review or if it was recorded as a result of their exit interview. 

We would like to have also seen the history of the employees satisfaction levels as recorded throughout their tenure as taken and recorded during the regular review process. 

**last_evaluation:** Categoric Ordinal Data ranked from 0 to 1. A value approaching one is a favorable review, a value approaching zero is unfavorable. We assume this value is the manager reported. 

It might have been helpful to see the values over time. 

**number_project:** This is a Numeric Discrete Data. It is the count of projects an employee is currently associated with.  We are making the assumption that this is the current number of projects a given employee is tasked with. 

It might have been helpful to see the roles the employee played in the projects the were assigned to. Were they the PM, the team leader, or were they relegated to a support role. 

**average_monthly:** This is a Numerical Continuous Data. The numerical value representing the number of hours an employee averages per month. We do not know the basis for average computation. Is this the current rolling one month average? Is this the employees total average weekly hours since the employee was hired? 

It would have like to have seen several averages, a total average hours since hire, a rolling annual average, a rolling quarterly average and a rolling monthly average. 

**time_spend_company:** This is a Numerical Discrete Data and represents the number of the full years that an employee has worked at the company. 

**work_accident:** This is Categorical Nominal Data and only tells us if an employee had a work related accident or not. It does not track the number of accidents nor does it track the severity of accidents. 

**left:** This Categorical Nominal Data, a label. 0 is the code for current with firm, 1 is separated from service. 

**promotion_last-5years:** Categorical Nominal Data. 0 labels no promotion, 1 represents a received a promotion. 

**department:** This is Categorical Data expressed textually. It is nominal in nature. We will need to transform this data.  Overtly, this value indicates which deparment the employee is a member of. 

Role within department might have been good data to see as well. 

**salary:** Categorical Data expresssed in text that is Ordinal in nature. High, Medium, Low. Depending on the method used, we are probably going to have to transform this data. 

I would have like to have seen information on raises and frequency of raises as well. 



#### 2.2 Data Understanding, Analysis & Preparation

Now that we have a thorough understanding of the data that we were give, let us load the training set and explore it. 

```{r}
train <- read.csv("training.csv", header = TRUE, sep = ",") 

```






```{r}
str(train)
```


```{r}
train[,3] <-as.factor(train[,3])
train[,5] <-as.factor(train[,5])
train[,6] <-as.factor(train[,6])
train[,7] <-as.factor(train[,7])
train[,8] <-as.factor(train[,8])
str(train)
```




```{r}
summary(train)
```




```{r}
library("Hmisc")

```

# separate the first 2000 observations (those who left)from the rest of the data

```{r}
separated <- train[ which(train$left == 1), ]

```

```{r}
str(separated)
```

```{r}
summary(separated)
```


```{r}
testing <- read.csv("TESTING.csv", header = TRUE, sep = ",")
```


```{r}
str(testing)
```

```{r}
testing[,3] <-as.factor(testing[,3])
testing[,5] <-as.factor(testing[,5])
testing[,6] <-as.factor(testing[,6])
testing[,7] <-as.factor(testing[,7])
testing[,8] <-as.factor(testing[,8])
str(testing)



```

```{r}
summary(testing)
```

```{r}
describe(testing)
```

# The Data is in and tested and checked. Now lets visualize the group that left. 
```{r}
ggplot(separated, aes(x = average_montly_hours, y =satisfaction_level)) + geom_jitter(aes(color = salary))
```
pay plays an issue...overworked underpaid. 


```{r}
ggplot(separated, aes(x = time_spend_company, y =satisfaction_level)) + geom_jitter(aes(color = salary))
```

```{r}
ggplot(separated, aes(x = last_evaluation, y =satisfaction_level)) + geom_jitter(aes(color = salary))
```


### 3. Modeling & Solving

based on what we have seen, I think it is about satisfaction with hours, pay, and and project.  

```{r}
mod_sep <- separated[, -(7:10) ]
mod <- lm(satisfaction_level ~., data = mod_sep)

step(mod)

mod <- lm(satisfaction_level ~ last_evaluation + number_project + average_montly_hours + time_spend_company, data = separated)
```
```{r}
model <-lm(formula = satisfaction_level ~ last_evaluation + number_project + 
    average_montly_hours + time_spend_company, data = mod_sep)

summary(model)

```


```{r}
library(ggfortify)
autoplot(model)
```

# lets try a logistic regression model 

```{r}
library(MASS)
library(dplyr)
```

```{r}
model <- glm(left ~., data = train, family = binomial) %>% stepAIC(trace=FALSE)
summary(model)
```

```{r}
prmodel2 <- glm(left ~ satisfaction_level + last_evaluation + number_project + average_montly_hours + time_spend_company + salary, family = binomial, data = train)
summary(prmodel2)
```


#### 3.1 Model Selection

We chose a stepped logistic regression model. Machine learning would be better.i COUL DHAVE TESTED THE FULL MODE.L

#### 3.2 Demonstrating Value & Accuracy

lETS TEST THE MODEL AND THEN CHECK GOODNESS OF FIT. 

```{r}
p1 <- predict(prmodel2, train, type = "response")
head(p1)
```

```{r}
pred1 <- ifelse(p1 > .05, 1, 0)
tab1 <- table(predicted =pred1, Actual = train$left)
tab1
```

```{r}
misclass <- (1-sum(diag(tab1))/sum(tab1))
misclass
```

```{r}
p2 <- predict(prmodel2, testing, type ="response")
pred2 <- ifelse(p2 > .05, 1, 0)
tab2 <- table(predicted = pred2, testing = testing$left)
tab2
```
```{r}
misclass <- (1-sum(diag(tab2))/sum(tab2))
misclass
```




### 4. Reporting and Communicating Results




